{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c63639bf",
   "metadata": {},
   "source": [
    "# Log Anomaly Detection mit Machine Learning\n",
    "\n",
    "Dieses Notebook demonstriert, wie Machine Learning f√ºr die Erkennung von Anomalien in Security-Logs eingesetzt werden kann:\n",
    "\n",
    "1. **Synthetische Logs generieren** - Normale und anomale Events simulieren\n",
    "2. **Feature Engineering** - Log-Daten f√ºr ML aufbereiten\n",
    "3. **Isolation Forest Training** - Anomalie-Modell trainieren\n",
    "4. **Anomaly Detection** - Verd√§chtige Events identifizieren\n",
    "5. **Report Generation** - Ergebnisse visualisieren und dokumentieren\n",
    "\n",
    "**Lernziele:**\n",
    "- Verstehen, wie ML bei Security-Monitoring hilft\n",
    "- Isolation Forest f√ºr Anomalie-Erkennung einsetzen\n",
    "- Log-Daten f√ºr ML-Modelle vorbereiten\n",
    "- Anomalie-Reports erstellen und interpretieren\n",
    "\n",
    "**Use Cases:**\n",
    "- Erkennung von ungew√∂hnlichen Login-Zeiten\n",
    "- Identifikation verd√§chtiger IP-Adressen\n",
    "- Auff√§llige Zugriffsmuster auf Ressourcen\n",
    "- Fr√ºherkennung von Insider-Threats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3976b4",
   "metadata": {},
   "source": [
    "## Schritt 1: Setup - Imports und Vorbereitung\n",
    "\n",
    "Zuerst importieren wir alle ben√∂tigten Bibliotheken und definieren die Pfade f√ºr unsere Demo-Dateien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import hashlib\n",
    "import random\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Pfade definieren\n",
    "logs_file = \"logs.csv\"\n",
    "report_file = \"anomalies_report.txt\"\n",
    "\n",
    "print(\"‚úì Imports erfolgreich\")\n",
    "print(f\"‚úì Log-Datei: {logs_file}\")\n",
    "print(f\"‚úì Report-Datei: {report_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d6e48c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Teil 1: Synthetische Log-Daten generieren\n",
    "\n",
    "## Normale vs. Anomale Events\n",
    "\n",
    "Wir simulieren Security-Logs mit zwei Arten von Events:\n",
    "\n",
    "**Normale Events:**\n",
    "- Geschehen w√§hrend typischer Arbeitszeiten (08:00-18:00)\n",
    "- Von bekannten Benutzern (alice, bob, charlie, diana)\n",
    "- Von internen IP-Adressen (10.x.x.x)\n",
    "- Typische Aktionen: login, logout, file_access\n",
    "\n",
    "**Anomale Events:**\n",
    "- Geschehen zu ungew√∂hnlichen Zeiten (nachts 00:00-05:00 oder 22:00-23:00)\n",
    "- Manchmal von unbekannten Benutzern (eve, mallory)\n",
    "- Von externen/ungew√∂hnlichen IP-Adressen (192.168.x.x)\n",
    "- Gleiche Aktionen, aber verd√§chtiger Kontext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5992596",
   "metadata": {},
   "source": [
    "## Helper-Funktion: Zuf√§llige IP-Adresse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3375c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_ip() -> str:\n",
    "    \"\"\"Generiert eine zuf√§llige IPv4-Adresse im privaten Bereich 10.0.0.0/8.\"\"\"\n",
    "    return f\"10.{random.randint(0, 255)}.{random.randint(0, 255)}.{random.randint(1, 254)}\"\n",
    "\n",
    "# Test\n",
    "print(f\"Beispiel IP: {random_ip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c470a799",
   "metadata": {},
   "source": [
    "## Normale Events generieren\n",
    "\n",
    "Wir erstellen 500 normale Log-Eintr√§ge w√§hrend typischer Arbeitszeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "users_normal = [\"andi\", \"dominik\", \"marcel\", \"diana\"]\n",
    "actions = [\"login\", \"logout\", \"file_access\"]\n",
    "resources = [\"/etc/passwd\", \"/var/log/syslog\", \"/home/shared/report.pdf\"]\n",
    "\n",
    "n_normal = 500\n",
    "rows: List[Dict[str, str]] = []\n",
    "start_date = dt.datetime.now(dt.timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "for _ in range(n_normal):\n",
    "    # Zeitpunkt zwischen 8 und 18 Uhr\n",
    "    hour = random.randint(8, 18)\n",
    "    minute = random.randint(0, 59)\n",
    "    ts = start_date + dt.timedelta(hours=hour, minutes=minute) + dt.timedelta(days=random.randint(0, 2))\n",
    "    \n",
    "    user = random.choice(users_normal)\n",
    "    ip = random_ip()\n",
    "    action = random.choices(actions, weights=[0.5, 0.2, 0.3])[0]\n",
    "    resource = random.choice(resources) if action == \"file_access\" else \"\"\n",
    "    \n",
    "    rows.append({\n",
    "        \"timestamp\": ts.isoformat(),\n",
    "        \"user\": user,\n",
    "        \"ip\": ip,\n",
    "        \"action\": action,\n",
    "        \"resource\": resource,\n",
    "        \"anomaly\": 0\n",
    "    })\n",
    "\n",
    "print(f\"‚úì {len(rows)} normale Events generiert\")\n",
    "print(f\"\\nBeispiel (erste 3 Events):\")\n",
    "for row in rows[:3]:\n",
    "    print(f\"  {row['timestamp'][:19]} | {row['user']:8} | {row['ip']:15} | {row['action']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5577746",
   "metadata": {},
   "source": [
    "## Anomale Events generieren\n",
    "\n",
    "Jetzt f√ºgen wir 10 verd√§chtige Events hinzu, die zu ungew√∂hnlichen Zeiten stattfinden oder von unbekannten IP-Adressen kommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8aa662",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_anom = [\"eve\", \"mallory\"]\n",
    "n_anom = 10\n",
    "\n",
    "for _ in range(n_anom):\n",
    "    # Ungew√∂hnliche Zeiten: nachts (0-5 Uhr) oder sp√§t abends (22-23 Uhr)\n",
    "    hour = random.choice([random.randint(0, 5), random.randint(22, 23)])\n",
    "    minute = random.randint(0, 59)\n",
    "    ts = start_date + dt.timedelta(hours=hour, minutes=minute) + dt.timedelta(days=random.randint(0, 2))\n",
    "    \n",
    "    user = random.choice(users_normal + users_anom)\n",
    "    # Andere IP-Range f√ºr anomale Events\n",
    "    ip = f\"192.168.{random.randint(0, 255)}.{random.randint(1, 254)}\"\n",
    "    action = random.choice(actions)\n",
    "    resource = random.choice(resources) if action == \"file_access\" else \"\"\n",
    "    \n",
    "    rows.append({\n",
    "        \"timestamp\": ts.isoformat(),\n",
    "        \"user\": user,\n",
    "        \"ip\": ip,\n",
    "        \"action\": action,\n",
    "        \"resource\": resource,\n",
    "        \"anomaly\": 1\n",
    "    })\n",
    "\n",
    "print(f\"‚úì {n_anom} anomale Events generiert\")\n",
    "print(f\"‚úì Total: {len(rows)} Events\")\n",
    "print(f\"\\nBeispiel (letzte 3 Events - anomal):\")\n",
    "for row in rows[-3:]:\n",
    "    print(f\"  {row['timestamp'][:19]} | {row['user']:8} | {row['ip']:15} | {row['action']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c098ae75",
   "metadata": {},
   "source": [
    "## DataFrame erstellen und speichern\n",
    "\n",
    "Wir konvertieren die Events in ein Pandas DataFrame und speichern sie als CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdedad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(logs_file, index=False)\n",
    "\n",
    "print(f\"‚úì Logs gespeichert in: {logs_file}\")\n",
    "print(f\"\\nDataFrame Info:\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Columns: {list(df.columns)}\")\n",
    "print(f\"\\nVerteilung:\")\n",
    "print(f\"  Normale Events: {(df['anomaly'] == 0).sum()}\")\n",
    "print(f\"  Anomale Events: {(df['anomaly'] == 1).sum()}\")\n",
    "print(f\"\\nErste 5 Zeilen:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b1e295",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Teil 2: Feature Engineering\n",
    "\n",
    "## Was ist Feature Engineering?\n",
    "\n",
    "Machine Learning Modelle arbeiten mit numerischen Daten. Wir m√ºssen unsere Log-Daten (Text, Timestamps) in Features umwandeln:\n",
    "\n",
    "**Zeitbasierte Features:**\n",
    "- Stunde des Tages (0-23)\n",
    "- Wochentag (0-6)\n",
    "\n",
    "**Kategorische Features (Hashing):**\n",
    "- Benutzername ‚Üí numerischer Hash\n",
    "- IP-Adresse ‚Üí numerischer Hash\n",
    "- Aktion ‚Üí numerischer Hash\n",
    "- Resource ‚Üí numerischer Hash\n",
    "\n",
    "**Warum Hashing?** Einfache Methode, um Text in konsistente Zahlen umzuwandeln."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d05e35e",
   "metadata": {},
   "source": [
    "## Hash-Funktion f√ºr kategorische Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_hash(value: str) -> float:\n",
    "    \"\"\"Konvertiert einen String in einen Float zwischen 0 und 1 via SHA256.\"\"\"\n",
    "    digest = hashlib.sha256(value.encode(\"utf-8\")).hexdigest()[:8]\n",
    "    return int(digest, 16) / 0xFFFFFFFF\n",
    "\n",
    "# Test\n",
    "print(\"Beispiel Hashes:\")\n",
    "print(f\"  alice  ‚Üí {feature_hash('alice'):.6f}\")\n",
    "print(f\"  bob    ‚Üí {feature_hash('bob'):.6f}\")\n",
    "print(f\"  login  ‚Üí {feature_hash('login'):.6f}\")\n",
    "print(f\"  logout ‚Üí {feature_hash('logout'):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f03d5",
   "metadata": {},
   "source": [
    "## Features aus Logs extrahieren\n",
    "\n",
    "Jetzt laden wir die Log-Datei und extrahieren alle Features f√ºr das ML-Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69aa55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(logs_file)\n",
    "\n",
    "# Zeitbasierte Features\n",
    "ts = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "df[\"hour\"] = ts.dt.hour\n",
    "df[\"day\"] = ts.dt.dayofweek\n",
    "\n",
    "# Kategorische Features hashen\n",
    "df[\"user_h\"] = df[\"user\"].apply(feature_hash)\n",
    "df[\"ip_h\"] = df[\"ip\"].apply(feature_hash)\n",
    "df[\"action_h\"] = df[\"action\"].apply(feature_hash)\n",
    "df[\"resource_h\"] = df[\"resource\"].fillna(\"\").apply(feature_hash)\n",
    "\n",
    "print(\"‚úì Feature Engineering abgeschlossen\")\n",
    "print(f\"\\nNeue Spalten:\")\n",
    "print(f\"  {list(df.columns)}\")\n",
    "print(f\"\\nBeispiel Features (erste 3 Zeilen):\")\n",
    "df[[\"hour\", \"day\", \"user_h\", \"ip_h\", \"action_h\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce275d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Teil 3: Isolation Forest Training\n",
    "\n",
    "## Was ist Isolation Forest?\n",
    "\n",
    "Isolation Forest ist ein un√ºberwachter ML-Algorithmus zur Anomalie-Erkennung:\n",
    "\n",
    "**Funktionsweise:**\n",
    "- Erstellt zuf√§llige Decision Trees\n",
    "- Anomalien sind leichter zu \"isolieren\" (weniger Splits n√∂tig)\n",
    "- Normale Daten ben√∂tigen mehr Splits\n",
    "- Score < 0: h√∂here Wahrscheinlichkeit f√ºr Anomalie\n",
    "\n",
    "**Vorteile:**\n",
    "- Keine gelabelten Daten n√∂tig\n",
    "- Schnell und effizient\n",
    "- Gut f√ºr hochdimensionale Daten\n",
    "\n",
    "**Parameter:**\n",
    "- `contamination`: Erwarteter Anteil von Anomalien (hier: 0.02 = 2%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699012f",
   "metadata": {},
   "source": [
    "## Modell trainieren und Anomalien vorhersagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaac38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Matrix f√ºr das Modell\n",
    "features = df[[\"hour\", \"day\", \"user_h\", \"ip_h\", \"action_h\", \"resource_h\"]]\n",
    "\n",
    "# Isolation Forest trainieren\n",
    "contamination = 0.02  # Erwarten 2% Anomalien\n",
    "model = IsolationForest(contamination=contamination, random_state=42)\n",
    "model.fit(features)\n",
    "\n",
    "# Anomalie-Scores und Predictions\n",
    "df[\"anomaly_score\"] = model.decision_function(features)\n",
    "df[\"anomaly_pred\"] = model.predict(features)\n",
    "\n",
    "# -1 = Anomalie, 1 = Normal\n",
    "anomalies = df[df[\"anomaly_pred\"] == -1]\n",
    "\n",
    "print(f\"‚úì Modell trainiert mit {len(df)} Events\")\n",
    "print(f\"\\nErgebnisse:\")\n",
    "print(f\"  Erkannte Anomalien: {len(anomalies)}\")\n",
    "print(f\"  Normale Events:     {(df['anomaly_pred'] == 1).sum()}\")\n",
    "print(f\"\\nScore-Statistiken:\")\n",
    "print(f\"  Min Score:  {df['anomaly_score'].min():.4f}\")\n",
    "print(f\"  Max Score:  {df['anomaly_score'].max():.4f}\")\n",
    "print(f\"  Mean Score: {df['anomaly_score'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30017d2",
   "metadata": {},
   "source": [
    "## Erkannte Anomalien anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87962cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üö® Erkannte Anomalien:\\n\")\n",
    "for idx, row in anomalies.iterrows():\n",
    "    print(f\"[{idx}] {row['timestamp'][:19]}\")\n",
    "    print(f\"    User:     {row['user']}\")\n",
    "    print(f\"    IP:       {row['ip']}\")\n",
    "    print(f\"    Action:   {row['action']}\")\n",
    "    print(f\"    Resource: {row['resource']}\")\n",
    "    print(f\"    Score:    {row['anomaly_score']:.4f}\")\n",
    "    print(f\"    Tats√§chlich anomal: {'JA' if row['anomaly'] == 1 else 'NEIN'}\")\n",
    "    print()\n",
    "\n",
    "# DataFrame mit relevanten Spalten\n",
    "anomalies[[\"timestamp\", \"user\", \"ip\", \"action\", \"resource\", \"anomaly_score\", \"anomaly\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c780e43",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Teil 4: Report Generation\n",
    "\n",
    "## Anomalie-Report erstellen\n",
    "\n",
    "Wir erstellen einen ausf√ºhrlichen Text-Report f√ºr Security-Teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(report_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    total = len(df)\n",
    "    num_anom = len(anomalies)\n",
    "    \n",
    "    # Header\n",
    "    f.write(\"=\" * 70 + \"\\n\")\n",
    "    f.write(\"               ANOMALY DETECTION REPORT\\n\")\n",
    "    f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "    \n",
    "    # Zusammenfassung\n",
    "    f.write(f\"Analysierte Events:      {total}\\n\")\n",
    "    f.write(f\"Erkannte Anomalien:      {num_anom}\\n\")\n",
    "    f.write(f\"Anomalierate:            {num_anom/total*100:.2f}%\\n\")\n",
    "    f.write(f\"Modell:                  Isolation Forest\\n\")\n",
    "    f.write(f\"Contamination Parameter: {contamination}\\n\")\n",
    "    f.write(\"\\n\" + \"-\" * 70 + \"\\n\\n\")\n",
    "    \n",
    "    if num_anom > 0:\n",
    "        f.write(\"VERD√ÑCHTIGE EVENTS:\\n\\n\")\n",
    "        for idx, row in anomalies.iterrows():\n",
    "            f.write(f\"Event #{idx}\\n\")\n",
    "            f.write(f\"  Timestamp:  {row['timestamp']}\\n\")\n",
    "            f.write(f\"  User:       {row['user']}\\n\")\n",
    "            f.write(f\"  IP-Adresse: {row['ip']}\\n\")\n",
    "            f.write(f\"  Aktion:     {row['action']}\\n\")\n",
    "            f.write(f\"  Resource:   {row['resource']}\\n\")\n",
    "            f.write(f\"  Score:      {row['anomaly_score']:.4f}\\n\")\n",
    "            f.write(f\"  Stunde:     {row['hour']}:00\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        f.write(\"Keine Anomalien gefunden.\\n\")\n",
    "    \n",
    "    f.write(\"-\" * 70 + \"\\n\")\n",
    "    f.write(\"Ende des Reports\\n\")\n",
    "\n",
    "print(f\"‚úì Report erstellt: {report_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b25302c",
   "metadata": {},
   "source": [
    "## Report anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1aadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(report_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    report_content = f.read()\n",
    "    print(report_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7de051",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Teil 5: Modell-Evaluation\n",
    "\n",
    "## Vergleich mit Ground Truth\n",
    "\n",
    "Da wir die Daten synthetisch generiert haben, wissen wir, welche Events tats√§chlich anomal sind. Vergleichen wir die Vorhersagen mit der Realit√§t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed0ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix manuell berechnen\n",
    "true_anomalies = df[df[\"anomaly\"] == 1]\n",
    "predicted_anomalies = df[df[\"anomaly_pred\"] == -1]\n",
    "\n",
    "# True Positives: Korrekt als Anomalie erkannt\n",
    "tp = len(df[(df[\"anomaly\"] == 1) & (df[\"anomaly_pred\"] == -1)])\n",
    "\n",
    "# False Positives: F√§lschlicherweise als Anomalie markiert\n",
    "fp = len(df[(df[\"anomaly\"] == 0) & (df[\"anomaly_pred\"] == -1)])\n",
    "\n",
    "# False Negatives: √úbersehene Anomalien\n",
    "fn = len(df[(df[\"anomaly\"] == 1) & (df[\"anomaly_pred\"] == 1)])\n",
    "\n",
    "# True Negatives: Korrekt als normal erkannt\n",
    "tn = len(df[(df[\"anomaly\"] == 0) & (df[\"anomaly_pred\"] == 1)])\n",
    "\n",
    "# Metriken\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"‚ïê\" * 50)\n",
    "print(\"           MODEL EVALUATION\")\n",
    "print(\"‚ïê\" * 50)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  True Positives:  {tp:3d}  (korrekt erkannte Anomalien)\")\n",
    "print(f\"  False Positives: {fp:3d}  (falsche Alarme)\")\n",
    "print(f\"  False Negatives: {fn:3d}  (√ºbersehene Anomalien)\")\n",
    "print(f\"  True Negatives:  {tn:3d}  (korrekt erkannte normale Events)\")\n",
    "print(f\"\\nMetriken:\")\n",
    "print(f\"  Precision: {precision:.2%}  (Wie viele erkannte Anomalien waren echt?)\")\n",
    "print(f\"  Recall:    {recall:.2%}  (Wie viele echte Anomalien wurden gefunden?)\")\n",
    "print(f\"  F1-Score:  {f1:.2%}  (Harmonic Mean von Precision & Recall)\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "if f1 > 0.8:\n",
    "    print(\"  ‚úì Exzellente Erkennung!\")\n",
    "elif f1 > 0.6:\n",
    "    print(\"  ‚úì Gute Erkennung\")\n",
    "elif f1 > 0.4:\n",
    "    print(\"  ‚ö† Moderate Erkennung - Tuning empfohlen\")\n",
    "else:\n",
    "    print(\"  ‚ö† Schwache Erkennung - Parameter anpassen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c3bc9f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Zusammenfassung & Best Practices\n",
    "\n",
    "## Was haben wir gelernt?\n",
    "\n",
    "**1. Synthetische Daten generieren**\n",
    "- Simulierte normale und anomale Security-Events\n",
    "- Zeitbasierte Muster f√ºr realistische Logs\n",
    "- Ground Truth f√ºr Evaluation verf√ºgbar\n",
    "\n",
    "**2. Feature Engineering f√ºr ML**\n",
    "- Zeitbasierte Features (Stunde, Wochentag)\n",
    "- Hashing f√ºr kategorische Variablen\n",
    "- Vorbereitung numerischer Features\n",
    "\n",
    "**3. Isolation Forest f√ºr Anomalie-Erkennung**\n",
    "- Un√ºberwachtes Learning - keine Labels n√∂tig\n",
    "- Contamination-Parameter bestimmt Sensitivit√§t\n",
    "- Decision Function liefert Anomalie-Scores\n",
    "\n",
    "**4. Report Generation**\n",
    "- Strukturierte Dokumentation f√ºr Security-Teams\n",
    "- √úbersichtliche Darstellung verd√§chtiger Events\n",
    "- Metriken f√ºr Modell-Evaluation\n",
    "\n",
    "## Best Practices f√ºr Production\n",
    "\n",
    "**Datenqualit√§t:**\n",
    "- Saubere, konsistente Log-Formate\n",
    "- Ausreichend historische Daten\n",
    "- Regelm√§√üige Daten-Updates\n",
    "\n",
    "**Feature Engineering:**\n",
    "- Dom√§nenspezifisches Wissen einbeziehen\n",
    "- Feature-Wichtigkeit analysieren\n",
    "- Neue Features iterativ testen\n",
    "\n",
    "**Modell-Tuning:**\n",
    "- Contamination-Parameter anpassen\n",
    "- Cross-Validation verwenden\n",
    "- False Positives minimieren (wichtig f√ºr SOC-Teams!)\n",
    "\n",
    "**Monitoring:**\n",
    "- Modell regelm√§√üig neu trainieren\n",
    "- Drift Detection implementieren\n",
    "- Feedback-Loop f√ºr falsche Alarme\n",
    "\n",
    "**Integration:**\n",
    "- SIEM-Integration f√ºr automatische Alerts\n",
    "- Ticketing-Systeme anbinden\n",
    "- Eskalationsprozesse definieren\n",
    "\n",
    "## N√§chste Schritte\n",
    "\n",
    "1. Mit realen Log-Daten experimentieren\n",
    "2. Weitere Features explorieren\n",
    "3. Alternative Algorithmen testen (One-Class SVM, Autoencoder)\n",
    "4. Threshold-Optimierung f√ºr Production\n",
    "5. Integration in Security-Pipeline\n",
    "\n",
    "## Weitere Ressourcen\n",
    "\n",
    "- Scikit-learn Isolation Forest Docs: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html\n",
    "- OWASP Logging Cheat Sheet: https://cheatsheetseries.owasp.org/cheatsheets/Logging_Cheat_Sheet.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heise-classroom-devsecops-ki1125-qbGNGHei-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
